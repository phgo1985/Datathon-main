# Datathon: 
### API de Entrevistas com Processamento de ZIPs, GeraÃ§Ã£o de Perguntas e AvaliaÃ§Ã£o via MLflow

Esta API em Flask processa arquivos ZIP contendo dados de candidatos e vagas, armazena-os em um banco SQLite, gera perguntas de entrevista usando **LangChain + OpenAI**, e avalia respostas registrando resultados no **MLflow**.

---

## ğŸš€ Funcionalidades

- **Processar mÃºltiplos arquivos ZIP** contendo JSONs de candidatos, prospects e vagas.
- **Consultar tabelas** do banco SQLite.
- **Iniciar entrevista** a partir do e-mail do candidato.
- **Gerar perguntas** para uma vaga especÃ­fica.
- **Avaliar entrevista** com cÃ¡lculo de compatibilidade semÃ¢ntica e registro no MLflow.
- **Rodar via Docker Compose** com ambiente isolado e replicÃ¡vel.

---

## ğŸ“‚ Estrutura de Pastas

```bash

DATATHON/
|    â””â”€â”€ app
|    |   â”œâ”€â”€ dados/
|    |   â”‚   â”œâ”€â”€ applicants.zip
|    |   â”‚   â”œâ”€â”€ prospects.zip
|    |   â”‚   â””â”€â”€ vagas.zip
|    |   â”œâ”€â”€ data/
|    |   â”‚   â”œâ”€â”€ extraidos
|    |   â”‚   â”‚   â”œâ”€â”€ applicants.json
|    |   â”‚   â”‚   â”œâ”€â”€ dados.db
|    |   â”‚   â”‚   â”œâ”€â”€ prospects.json
|    |   â”‚   â”‚   â””â”€â”€ vagas.json
|    |   â”‚   â””â”€â”€ EDA dados db.ipynb
|    |   â”œâ”€â”€ frontend/
|    |   â”‚   â””â”€â”€ front.py
|    |   â”œâ”€â”€ monitoring/
|    |   â”‚   â””â”€â”€ drift_monitor.ipynb
|    |   â”œâ”€â”€ utils/
|    |   â”‚   â”œâ”€â”€ __init__.py
|    |   â”‚   â”œâ”€â”€ calcular_compatibilidade_emb.py
|    |   â”‚   â”œâ”€â”€ db_path.py
|    |   â”‚   â”œâ”€â”€ etl_zip.py
|    |   â”‚   â”œâ”€â”€ flatten_json.py
|    |   â”‚   â”œâ”€â”€ gerar_perguntas_para_vaga.py
|    |   â”‚   â”œâ”€â”€ montar_df_entrevista.py
|    |   â”‚   â””â”€â”€ semantic_engine.py
|    |   â”œâ”€â”€.dockerignore
|    |   â”œâ”€â”€.env
|    |   â”œâ”€â”€ app.py
|    |   â”œâ”€â”€ docker-compose.yml
|    |   â”œâ”€â”€ Docekrfile
|    |   â”œâ”€â”€ Docekrfile.streamlit
|    |   â”œâ”€â”€ requirements.txt
|    â””â”€â”€ mlruns/
|    â””â”€â”€ .gitignore
|    â””â”€â”€ README.md
â””â”€â”€
```

---

## âš™ï¸ PrÃ©-requisitos

- Python 3.11
VersÃµes superiores (como 3.12 ou 3.13) podem causar conflitos de dependÃªncia, especialmente com bibliotecas como numpy, pydantic, e ml3-drift. VocÃª pode baixar o instalador oficial aqui:

ğŸ”— https://www.python.org/downloads/release/python-3118/

- Conta e chave de API da OpenAI
- MLflow instalado
- Docker instalado
- Docker Compose instalado

### âš ï¸ Compatibilidade com LangChain e Drift

Este projeto usa `LangChain` com `pydantic 2.x`, portanto o monitoramento de drift foi implementado com `ml3-drift`, que Ã© compatÃ­vel com essa versÃ£o.  
Evite usar `alibi-detect`, pois ele depende de `pydantic 1.x` e causa conflitos com LangChain.
---

## ğŸ¯ Entrevista via Streamlit

Este projeto inclui uma interface interativa em Streamlit para que candidatos possam realizar entrevistas diretamente pelo navegador. A aplicaÃ§Ã£o se conecta ao backend Flask para:
- Receber o e-mail do candidato
- Gerar perguntas personalizadas com base na vaga
- Coletar respostas e avaliar compatibilidade
- Exibir o resultado da entrevista em tempo real
A interface estÃ¡ localizada em frontend/front.py.

ComunicaÃ§Ã£o entre serviÃ§os
O Streamlit se comunica com o Flask via http://web:5000, usando o nome do serviÃ§o Docker como hostname.

ğŸ§ª Testando a entrevista
- Acesse http://localhost:8501
- Digite o e-mail do candidato
- Escolha a vaga (se houver mais de uma)
- Responda Ã s perguntas
- Veja o resultado da entrevista com os scores e compatibilidades

___

## ğŸ³ Docker Compose

Para rodar o projeto com Docker:

### 1. `Dockerfile`

```Dockerfile
FROM python:3.12-slim
WORKDIR /app
COPY . .
RUN pip install --upgrade pip && pip install --no-cache-dir -r requirements.txt
EXPOSE 5000
CMD ["python", "app.py"]
```

### 2. `Docker-compose.yml`


```Yaml
version: '3.12'

services:
  web:
    build: .
    ports:
      - "5000:5000"
    volumes:
      - .:/app
    working_dir: /app
    env_file:
      - .env
    command: python app.py
```

### 3. `Rodar o projeto`

docker-compose up --build

Certificar que estÃ¡ rodando dentro do diretÃ³rio \app.

---

## ğŸ“¦ InstalaÃ§Ã£o

1. **Clonar o repositÃ³rio**:
   ```bash
   git clone https://seu-repositorio.git
   cd projeto

2. **Criar ambiente virtual**:
    ```bash
    python -m venv venv
    source venv/bin/activate   # Linux/Mac
    venv\Scripts\activate      # Windows
     ```

3. **Instalar dependÃªncias**:
    ```bash
    pip install -r requirements.txt
     ```

4. **Configurar variÃ¡veis de ambiente: Crie um arquivo .env na raiz com**:
  ```bash
    OPENAI_API_KEY=sua_chave_openai_aqui
  ```

---

ğŸ“œ Endpoints
1ï¸âƒ£ POST /processar_todos_zips
Processa todos os arquivos ZIP de uma pasta e salva no banco SQLite.
Body (JSON):
{
  "pasta_zips": "caminho/para/pasta",
  "destino": "caminho/para/destino",
  "db_path": "caminho/para/dados.db"
}


Resposta:
{
  "mensagem": "Todos os ZIPs foram processados.",
  "tabelas_salvas": ["applicants", "prospects", "vagas"],
  "banco": "dados.db",
  "zips_processados": ["arquivo1.zip", "arquivo2.zip"]
}


2ï¸âƒ£ GET /consultar/<tabela>
Consulta atÃ© 50 registros de uma tabela.
Exemplo:
GET /consultar/applicants


3ï¸âƒ£ POST /iniciar-entrevista
Inicia entrevista a partir do e-mail do candidato.
Body:
{
  "email": "candidato@exemplo.com"
}


Resposta:
- Se houver 1 vaga:
{
  "status": "ok",
  "nome": "Fulano",
  "titulo_vaga": "Analista de Sistemas",
  "objetivo_vaga": "...",
  "competencias": "...",
  "resumo": "...",
  "perguntas": ["Pergunta 1", "..."]
}


- Se houver mais de uma vaga:
{
  "status": "escolha_vaga",
  "nome": "Fulano",
  "vagas": [
    {"indice": 0, "titulo_vaga": "Vaga A"},
    {"indice": 1, "titulo_vaga": "Vaga B"}
  ]
}


4ï¸âƒ£ POST /gerar-perguntas
Gera perguntas para uma vaga especÃ­fica.
Body:
{
  "email": "candidato@exemplo.com",
  "indice_vaga": 0
}


Resposta:
{
  "status": "ok",
  "nome": "Fulano",
  "titulo_vaga": "Analista de Sistemas",
  "objetivo_vaga": "...",
  "competencias": "...",
  "resumo": "...",
  "perguntas": ["Pergunta 1", "..."]
}


5ï¸âƒ£ POST /avaliar-entrevista
Avalia respostas e registra no MLflow.
Body:
{
  "email": "candidato@exemplo.com",
  "indice_vaga": 0,
  "perguntas": ["Pergunta 1", "..."],
  "respostas": ["Resposta 1", "..."]
}


Resposta:
{
  "status": "ok",
  "nome": "Fulano",
  "titulo_vaga": "Analista de Sistemas",
  "resultado": "APTO",
  "score_compatibilidade": 82.5,
  "score_compatibilidade_detalhada": 70,
  "requisitos_mais_compatÃ­veis": ["comunicaÃ§Ã£o eficaz", "trabalho em equipe"],
  "requisitos_menos_compatÃ­veis": ["experiÃªncia com AWS"]
}

Compatibilidade semÃ¢ntica com embeddings
A funÃ§Ã£o calcular_compatibilidade_detalhada usa sentence-transformers para comparar requisitos com:
- ExperiÃªncia tÃ©cnica
- Respostas Ã s perguntas
- Resumo do currÃ­culo (cv_pt)
Ela retorna:
- âœ… Score mÃ©dio de compatibilidade
- âœ… Lista de requisitos mais compatÃ­veis
- âœ… Lista de requisitos menos compatÃ­veis

---

ğŸ§ª Testando no Postman
Fluxo sugerido:
- /iniciar-entrevista â†’ pega Ã­ndice da vaga.
- /gerar-perguntas â†’ obtÃ©m perguntas.
- /avaliar-entrevista â†’ envia perguntas e respostas.
ğŸ’¡ VocÃª pode usar Scripts Postâ€‘response no Postman para salvar automaticamente as perguntas e reaproveitar na prÃ³xima requisiÃ§Ã£o.

---

ğŸ“Š IntegraÃ§Ã£o com MLflow
Cada avaliaÃ§Ã£o cria um run no MLflow com:
- ParÃ¢metros: nome, email, vaga, objetivo, resultado, competÃªncias.
- MÃ©trica: compatibilidade tÃ©cnica (%).
- Artefatos: perguntas e respostas em .txt.
Para visualizar:
mlflow ui


Acesse: http://127.0.0.1:5000

---

ğŸ“„ LicenÃ§a
Este projeto Ã© de uso interno/educacional. Ajuste conforme necessÃ¡rio para produÃ§Ã£o.

---
